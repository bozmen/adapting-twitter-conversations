{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "926cb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "# total rel score:1.004891304347826\n",
    "# specific rel score:1.002625837320574\n",
    "\n",
    "train_files = ['099', '136', '077', '162', '059', '528', '054', '500', '016', '551', '114', '007', '192', '143', '543', '171', '191', '181', '110', '060', '045', '177', '063', '068', '078', '153', '127', '558', '515', '118', '027', '547', '142', '089', '173', '180', '028', '195', '128', '513', '130', '152', '120', '119', '013', '182', '145', '024', '167', '511', '144', '134', '514', '508', '510', '189', '125', '083', '070', '141', '065', '187', '122', '151', '504', '035', '116', '549', '102', '053', '503', '185', '155', '149', '176', '093', '183', '043', '055', '166', '108', '034', '168', '017', '098', '066', '188', '086', '025', '069', '104', '096', '117', '179', '088', '097', '051', '178', '160', '133', '029', '163', '107', '129', '076', '022', '100', '154', '193', '006', '158', '137', '169', '001', '505', '094', '165', '056', '140', '015', '109', '030', '534', '075', '039', '200', '023', '050', '040', '194', '019', '058', '002', '150', '033', '071', '090', '064', '523', '164', '106', '011', '073', '052', '156', '080', '012', '084', '507', '157', '174']\n",
    "test_files = ['085', '101', '074', '082', '190', '081', '036', '004', '138', '112', '172', '516', '010', '091', '196', '557', '087', '184', '092']\n",
    "dev_files = ['555', '121', '005', '123', '072', '552', '020', '148', '502', '048', '159', '105', '037', '003']\n",
    "\n",
    "DATA_FOLDER = '../twitter_partitioned/'\n",
    "PARSES_FOLDER = '/home/burak/Desktop/thesis/code/IM/twitter_data/raw/tokenized'\n",
    "CONLL_FORMAT_FILE = '/home/burak/Desktop/thesis/code/IM/thesis/conll_relations_raw_fixed_spans.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b8b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H%M%S\")\n",
    "\n",
    "partition_path = DATA_FOLDER + '/partition_' + current_time\n",
    "os.makedirs(partition_path)\n",
    "os.makedirs(partition_path + '/en.dev')\n",
    "os.makedirs(partition_path + '/en.test')\n",
    "os.makedirs(partition_path + '/en.train')\n",
    "\n",
    "with open(partition_path + '/en.dev/parses.json', 'w') as dev_parses_file, \\\n",
    "    open(partition_path + '/en.test/parses.json', 'w') as test_parses_file, \\\n",
    "    open(partition_path + '/en.train/parses.json', 'w') as train_parses_file, \\\n",
    "    open(partition_path + '/en.dev/relations.json', 'w') as dev_relations_file, \\\n",
    "    open(partition_path + '/en.test/relations.json', 'w') as test_relations_file, \\\n",
    "    open(partition_path + '/en.train/relations.json', 'w') as train_relations_file:\n",
    "            dev_parses = dict()\n",
    "            test_parses = dict()\n",
    "            train_parses = dict()\n",
    "            for file_name in os.listdir(PARSES_FOLDER):\n",
    "                # parses\n",
    "                with open(PARSES_FOLDER + '/' + file_name, 'r') as file:\n",
    "                    obj = json.load(file)\n",
    "                    file_prefix = file_name[:3]\n",
    "                    if file_prefix in train_files:\n",
    "                        train_parses[file_name] = obj\n",
    "                    if file_prefix in test_files:\n",
    "                        test_parses[file_name] = obj\n",
    "                    if file_prefix in dev_files:\n",
    "                        dev_parses[file_name] = obj\n",
    "                # relations\n",
    "                with open(CONLL_FORMAT_FILE, 'r') as file:\n",
    "                    file_prefix = file_name[:3]\n",
    "                    all_docs = json.load(file)\n",
    "                    cur_doc = all_docs[file_name]\n",
    "                    for relation in cur_doc:\n",
    "                        if file_prefix in train_files:\n",
    "                            train_relations_file.write(json.dumps(relation))\n",
    "                            train_relations_file.write('\\n')\n",
    "                        if file_prefix in test_files:\n",
    "                            test_relations_file.write(json.dumps(relation))\n",
    "                            test_relations_file.write('\\n')\n",
    "                        if file_prefix in dev_files:\n",
    "                            dev_relations_file.write(json.dumps(relation))\n",
    "                            dev_relations_file.write('\\n')\n",
    "                    \n",
    "            dev_parses_file.write(json.dumps(dev_parses))\n",
    "            test_parses_file.write(json.dumps(test_parses))\n",
    "            train_parses_file.write(json.dumps(train_parses))\n",
    "            \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5be0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
